# RAG System - Vietnamese PDF Q&A

Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) vá»›i Hybrid Search cho tÃ i liá»‡u PDF tiáº¿ng Viá»‡t.

## âœ¨ TÃ­nh nÄƒng

- ğŸ” **Hybrid Search**: Káº¿t há»£p Semantic (vector) + Keyword (BM25) + Reciprocal Rank Fusion
- ğŸ¤– **LLM**: Ollama vá»›i model tiáº¿ng Viá»‡t (`Tuanpham/t-visstar-7b:latest`)
- ğŸ“Š **Vector Store**: Qdrant cho tÃ¬m kiáº¿m nhanh
- ğŸ¨ **UI**: Streamlit giao diá»‡n Ä‘Æ¡n giáº£n, táº­p trung
- ğŸ‡»ğŸ‡³ **Vietnamese Support**: Tá»‘i Æ°u cho tiáº¿ng Viá»‡t

## ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Upload    â”‚
â”‚   PDFs      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Processing     â”‚
â”‚  (RecursiveChar     â”‚
â”‚   TextSplitter)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Qdrant     â”‚   â”‚  BM25 Index â”‚
â”‚   (Vector    â”‚   â”‚  (Keyword)  â”‚
â”‚    Store)    â”‚   â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â”‚    User Query    â”‚
       â–¼                  â–¼
       â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Hybrid Search  â”‚
       â”‚  (RRF Fusion)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚     Ollama     â”‚
       â”‚  (Vietnamese   â”‚
       â”‚      LLM)      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
          Vietnamese Answer
```

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u

- Python 3.10+
- Docker (cho Qdrant)
- Ollama

### BÆ°á»›c 1: Clone repository

```bash
git clone https://github.com/yourusername/rag-vietnamese-qa.git
cd rag-vietnamese-qa
```

### BÆ°á»›c 2: Táº¡o virtual environment

```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### BÆ°á»›c 4: Khá»Ÿi Ä‘á»™ng Qdrant

```bash
docker run -d -p 6333:6333 -p 6334:6334 \
  -v ./data/qdrant_storage:/qdrant/storage \
  --name qdrant_rag \
  qdrant/qdrant
```

### BÆ°á»›c 5: CÃ i Ä‘áº·t Ollama model

```bash
ollama pull Tuanpham/t-visstar-7b:latest
```

### BÆ°á»›c 6: Cháº¡y á»©ng dá»¥ng

```bash
streamlit run app.py
```

Truy cáº­p: `http://localhost:8501`

## âš™ï¸ Cáº¥u hÃ¬nh

File `.env`:
```env
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=  # Äá»ƒ trá»‘ng náº¿u dÃ¹ng local
```

File `config.py`:
```python
CHUNK_SIZE = 1000              # KÃ­ch thÆ°á»›c chunk (kÃ½ tá»±)
CHUNK_OVERLAP = 200            # Overlap giá»¯a chunks
OLLAMA_MODEL = "Tuanpham/t-visstar-7b:latest"
LLM_TEMPERATURE = 0.3          # Nhiá»‡t Ä‘á»™ LLM (tháº¥p = focused)
SEARCH_TYPE = "hybrid"         # Hybrid search máº·c Ä‘á»‹nh
```

## ğŸ“– Sá»­ dá»¥ng

1. **Upload PDF**: KÃ©o tháº£ file PDF vÃ o giao diá»‡n
2. **Há»i Ä‘Ã¡p**: Nháº­p cÃ¢u há»i tiáº¿ng Viá»‡t
3. **Xem nguá»“n**: Kiá»ƒm tra nguá»“n trÃ­ch dáº«n

## ğŸ”§ CÃ´ng nghá»‡

| Component | Technology |
|-----------|-----------|
| **Frontend** | Streamlit |
| **LLM** | Ollama (Tuanpham/t-visstar-7b) |
| **Vector DB** | Qdrant |
| **Embeddings** | sentence-transformers/all-MiniLM-L6-v2 |
| **Text Splitting** | LangChain RecursiveCharacterTextSplitter |
| **Keyword Search** | BM25Okapi (rank-bm25) |
| **Fusion** | Reciprocal Rank Fusion |

## ğŸ“Š Hiá»‡u suáº¥t

- **Hybrid Search**: Äá»™ chÃ­nh xÃ¡c cao hÆ¡n 15-20% so vá»›i semantic-only
- **Response Time**: ~3-5 giÃ¢y (phá»¥ thuá»™c Ollama)
- **Memory**: ~2GB RAM (embedding model + LLM)

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
RAG/
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ rag_engine.py          # Core RAG logic
â”œâ”€â”€ llm_handler.py         # Ollama integration
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ utils.py               # Utilities
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ .gitignore            # Git ignore
â””â”€â”€ data/                  # Data directory
    â”œâ”€â”€ uploaded_pdfs/     # User PDFs
    â””â”€â”€ qdrant_db/         # Qdrant storage
```

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh! Vui lÃ²ng:
1. Fork repository
2. Táº¡o branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Má»Ÿ Pull Request

## ğŸ™ Credits

- **Ollama**: https://ollama.com
- **Qdrant**: https://qdrant.tech
- **LangChain**: https://langchain.com
- **Vietnamese LLM**: Tuanpham/t-visstar-7b